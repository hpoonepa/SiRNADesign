{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  siRNA               sequence              structure  mfe\n",
      "0    A1  CUAAUAUGUUAAUUGAUUUAU  .....................  0.0\n",
      "1    A2  AAUAUGUUAAUUGAUUUAUAC  .....................  0.0\n",
      "2    A3  GAUUUAUACAAUUCCUUUCAA  .....................  0.0\n"
     ]
    }
   ],
   "source": [
    "import RNA  # ViennaRNA Python package\n",
    "import pandas as pd\n",
    "\n",
    "# Example DataFrame with sequences\n",
    "data = {'siRNA': ['A1', 'A2', 'A3'], \n",
    "        'sequence': ['CUAAUAUGUUAAUUGAUUUAU', 'AAUAUGUUAAUUGAUUUAUAC', 'GAUUUAUACAAUUCCUUUCAA']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "def calculate_structure_and_energy(sequence):\n",
    "    # Ensure the sequence is in uppercase\n",
    "    sequence = sequence.upper()\n",
    "    # Create a ViennaRNA fold compound\n",
    "    fc = RNA.fold_compound(sequence)\n",
    "    # Compute the MFE and structure\n",
    "    structure, mfe = fc.mfe()\n",
    "    return structure, mfe\n",
    "\n",
    "# Apply the function to the DataFrame and store the results\n",
    "df['structure'], df['mfe'] = zip(*df['sequence'].apply(calculate_structure_and_energy))\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  siRNA               sequence      mRNA  efficacy\n",
      "0    A1  CUAAUAUGUUAAUUGAUUUAU  BD135193     0.462\n",
      "1    A2  AAUAUGUUAAUUGAUUUAUAC  BD135193     0.384\n",
      "2    A3  GAUUUAUACAAUUCCUUUCAA  BD135193     0.514\n",
      "3    A4  CAAUUCCUUUCAAUUUUAUCU  BD135193     0.364\n",
      "4    A5  CAGACCAAAAUUAAAUAAGAA  BD135193     0.522\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load efficacy data\n",
    "efficacy_df = pd.read_csv(\"sirna_mrna_efficacy.csv\")\n",
    "\n",
    "# Load siRNA sequences from the FASTA file\n",
    "from Bio import SeqIO\n",
    "\n",
    "sirna_sequences = []\n",
    "with open(\"sirna_1.fas\", \"r\") as fasta_file:\n",
    "    for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "        sirna_sequences.append({\"siRNA\": record.id, \"sequence\": str(record.seq).upper()})\n",
    "\n",
    "sirna_df = pd.DataFrame(sirna_sequences)\n",
    "\n",
    "# Merge siRNA sequences into the efficacy dataset\n",
    "merged_df = pd.merge(sirna_df, efficacy_df, on=\"siRNA\", how=\"inner\")\n",
    "\n",
    "# Reorder columns to place 'sequence' between 'siRNA' and 'mRNA'\n",
    "columns = [\"siRNA\", \"sequence\", \"mRNA\", \"efficacy\"]\n",
    "merged_df = merged_df[columns]\n",
    "\n",
    "# Save or display the updated dataset\n",
    "print(merged_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  siRNA               sequence      mRNA  efficacy  gc_content  \\\n",
      "0    A1  CUAAUAUGUUAAUUGAUUUAU  BD135193     0.462   14.285714   \n",
      "1    A2  AAUAUGUUAAUUGAUUUAUAC  BD135193     0.384   14.285714   \n",
      "2    A3  GAUUUAUACAAUUCCUUUCAA  BD135193     0.514   23.809524   \n",
      "3    A4  CAAUUCCUUUCAAUUUUAUCU  BD135193     0.364   23.809524   \n",
      "4    A5  CAGACCAAAAUUAAAUAAGAA  BD135193     0.522   23.809524   \n",
      "\n",
      "   rule_1_gc_range  rule_2_u_position_1  rule_3_a_positions_1_10  \\\n",
      "0            False                False                    False   \n",
      "1            False                False                     True   \n",
      "2            False                False                    False   \n",
      "3            False                False                    False   \n",
      "4            False                False                    False   \n",
      "\n",
      "   rule_4_no_g_14_18  rule_5_no_a_19  rule_6_motifs_present  \\\n",
      "0               True            True                  False   \n",
      "1               True            True                  False   \n",
      "2               True            True                  False   \n",
      "3               True            True                   True   \n",
      "4               True            True                  False   \n",
      "\n",
      "   rule_7_motifs_absent  high_gibbs_1_4  low_gibbs_18_19  avoid_folding  \n",
      "0                  True            True             True           True  \n",
      "1                  True            True             True           True  \n",
      "2                  True            True             True           True  \n",
      "3                  True            True             True           True  \n",
      "4                  True            True             True           True  \n"
     ]
    }
   ],
   "source": [
    "def calculate_gc_content(sequence):\n",
    "    \"\"\"Calculate GC content as a percentage.\"\"\"\n",
    "    gc_count = sequence.count(\"G\") + sequence.count(\"C\")\n",
    "    return (gc_count / len(sequence)) * 100\n",
    "\n",
    "def calculate_features(row):\n",
    "    sequence = row[\"sequence\"]\n",
    "    antisense = sequence[::-1]  # Reverse sequence for antisense strand\n",
    "    \n",
    "    features = {\n",
    "        \"gc_content\": calculate_gc_content(sequence),\n",
    "        \"rule_1_gc_range\": 35 <= calculate_gc_content(sequence) <= 73,\n",
    "        \"rule_2_u_position_1\": antisense[-1] == \"U\",\n",
    "        \"rule_3_a_positions_1_10\": antisense[-1] == \"A\" and antisense[-10] == \"A\",\n",
    "        \"rule_4_no_g_14_18\": antisense[-14] != \"G\" and antisense[-18] != \"G\",\n",
    "        \"rule_5_no_a_19\": antisense[-19] != \"A\",\n",
    "        \"rule_6_motifs_present\": any(motif in antisense for motif in [\"UCU\", \"UCCG\"]),\n",
    "        \"rule_7_motifs_absent\": not any(motif in antisense for motif in [\"ACGA\", \"GCC\", \"GUGG\"]),\n",
    "        # Placeholder for Gibbs energy changes and folding:\n",
    "        \"high_gibbs_1_4\": True,  # Dummy value\n",
    "        \"low_gibbs_18_19\": True,  # Dummy value\n",
    "        \"avoid_folding\": True,  # Dummy value\n",
    "    }\n",
    "    return features\n",
    "\n",
    "# Apply the feature engineering\n",
    "features = merged_df.apply(calculate_features, axis=1)\n",
    "features_df = pd.DataFrame(features.tolist())\n",
    "\n",
    "# Combine features with the original dataset\n",
    "siRNA_data_with_features = pd.concat([merged_df, features_df], axis=1)\n",
    "\n",
    "print(siRNA_data_with_features.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harsha/anaconda3/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.0553\n",
      "Epoch 2, Loss: 0.0410\n",
      "Epoch 3, Loss: 0.0405\n",
      "Epoch 4, Loss: 0.0404\n",
      "Epoch 5, Loss: 0.0409\n",
      "Epoch 6, Loss: 0.0404\n",
      "Epoch 7, Loss: 0.0415\n",
      "Epoch 8, Loss: 0.0400\n",
      "Epoch 9, Loss: 0.0407\n",
      "Epoch 10, Loss: 0.0412\n",
      "Epoch 11, Loss: 0.0400\n",
      "Epoch 12, Loss: 0.0405\n",
      "Epoch 13, Loss: 0.0404\n",
      "Epoch 14, Loss: 0.0395\n",
      "Epoch 15, Loss: 0.0399\n",
      "Epoch 16, Loss: 0.0389\n",
      "Epoch 17, Loss: 0.0398\n",
      "Epoch 18, Loss: 0.0395\n",
      "Epoch 19, Loss: 0.0393\n",
      "Epoch 20, Loss: 0.0394\n",
      "Epoch 21, Loss: 0.0402\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 164\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;66;03m# Training loop\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m50\u001b[39m):\n\u001b[0;32m--> 164\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[56], line 115\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, optimizer, criterion)\u001b[0m\n\u001b[1;32m    113\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m    114\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 115\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m    116\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    117\u001b[0m     output \u001b[38;5;241m=\u001b[39m model(data)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch_geometric/loader/dataloader.py:27\u001b[0m, in \u001b[0;36mCollater.__call__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     25\u001b[0m elem \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, BaseData):\n\u001b[0;32m---> 27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_data_list\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfollow_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexclude_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexclude_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m default_collate(batch)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch_geometric/data/batch.py:97\u001b[0m, in \u001b[0;36mBatch.from_data_list\u001b[0;34m(cls, data_list, follow_batch, exclude_keys)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_data_list\u001b[39m(\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     87\u001b[0m     exclude_keys: Optional[List[\u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     88\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[1;32m     89\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Constructs a :class:`~torch_geometric.data.Batch` object from a\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;124;03m    list of :class:`~torch_geometric.data.Data` or\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;124;03m    :class:`~torch_geometric.data.HeteroData` objects.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;124;03m    Will exclude any keys given in :obj:`exclude_keys`.\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 97\u001b[0m     batch, slice_dict, inc_dict \u001b[38;5;241m=\u001b[39m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m        \u001b[49m\u001b[43mincrement\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexclude_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m     batch\u001b[38;5;241m.\u001b[39m_num_graphs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(data_list)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    107\u001b[0m     batch\u001b[38;5;241m.\u001b[39m_slice_dict \u001b[38;5;241m=\u001b[39m slice_dict  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch_geometric/data/collate.py:109\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(cls, data_list, increment, add_batch, follow_batch, exclude_keys)\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m# Collate attributes into a unified representation:\u001b[39;00m\n\u001b[0;32m--> 109\u001b[0m value, slices, incs \u001b[38;5;241m=\u001b[39m \u001b[43m_collate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mincrement\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;66;03m# If parts of the data are already on GPU, make sure that auxiliary\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m# data like `batch` or `ptr` are also created on GPU:\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, Tensor) \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mis_cuda:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch_geometric/data/collate.py:167\u001b[0m, in \u001b[0;36m_collate\u001b[0;34m(key, values, data_list, stores, increment)\u001b[0m\n\u001b[1;32m    165\u001b[0m     values \u001b[38;5;241m=\u001b[39m [value\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m value \u001b[38;5;129;01min\u001b[39;00m values]\n\u001b[1;32m    166\u001b[0m sizes \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([value\u001b[38;5;241m.\u001b[39msize(cat_dim \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m value \u001b[38;5;129;01min\u001b[39;00m values])\n\u001b[0;32m--> 167\u001b[0m slices \u001b[38;5;241m=\u001b[39m \u001b[43mcumsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43msizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m increment:\n\u001b[1;32m    169\u001b[0m     incs \u001b[38;5;241m=\u001b[39m get_incs(key, values, data_list, stores)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch_geometric/utils/functions.py:23\u001b[0m, in \u001b[0;36mcumsum\u001b[0;34m(x, dim)\u001b[0m\n\u001b[1;32m     20\u001b[0m size \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39msize()[:dim] \u001b[38;5;241m+\u001b[39m (x\u001b[38;5;241m.\u001b[39msize(dim) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, ) \u001b[38;5;241m+\u001b[39m x\u001b[38;5;241m.\u001b[39msize()[dim \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m     21\u001b[0m out \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mnew_empty(size)\n\u001b[0;32m---> 23\u001b[0m \u001b[43mout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnarrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mzero_()\n\u001b[1;32m     24\u001b[0m torch\u001b[38;5;241m.\u001b[39mcumsum(x, dim\u001b[38;5;241m=\u001b[39mdim, out\u001b[38;5;241m=\u001b[39mout\u001b[38;5;241m.\u001b[39mnarrow(dim, \u001b[38;5;241m1\u001b[39m, x\u001b[38;5;241m.\u001b[39msize(dim)))\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "\n",
    "# ================================\n",
    "# Step 1: Feature Engineering\n",
    "# ================================\n",
    "def calculate_gc_content(sequence):\n",
    "    \"\"\"Calculate GC content as a percentage.\"\"\"\n",
    "    gc_count = sequence.count(\"G\") + sequence.count(\"C\")\n",
    "    return (gc_count / len(sequence)) * 100 if len(sequence) > 0 else 0\n",
    "\n",
    "def calculate_features(row):\n",
    "    \"\"\"Apply feature engineering rules to a sequence.\"\"\"\n",
    "    sequence = row[\"sequence\"]\n",
    "    antisense = sequence[::-1]  # Reverse sequence for antisense strand\n",
    "    sequence_length = len(sequence)\n",
    "\n",
    "    features = {\n",
    "        \"gc_content\": calculate_gc_content(sequence),\n",
    "        \"rule_1_gc_range\": 35 <= calculate_gc_content(sequence) <= 73,\n",
    "        \"rule_2_u_position_1\": antisense[-1] == \"U\" if sequence_length >= 1 else False,\n",
    "        \"rule_3_a_positions_1_10\": (antisense[-1] == \"A\" and antisense[-10] == \"A\") if sequence_length >= 10 else False,\n",
    "        \"rule_4_no_g_14_18\": (antisense[-14] != \"G\" and antisense[-18] != \"G\") if sequence_length >= 18 else False,\n",
    "        \"rule_5_no_a_19\": antisense[-19] != \"A\" if sequence_length >= 19 else False,\n",
    "        \"rule_6_motifs_present\": any(motif in antisense for motif in [\"UCU\", \"UCCG\"]),\n",
    "        \"rule_7_motifs_absent\": not any(motif in antisense for motif in [\"ACGA\", \"GCC\", \"GUGG\"]),\n",
    "        \"high_gibbs_1_4\": True,  # Placeholder\n",
    "        \"low_gibbs_18_19\": True,  # Placeholder\n",
    "        \"avoid_folding\": True,  # Placeholder\n",
    "    }\n",
    "    return features\n",
    "\n",
    "def prepare_feature_data(df):\n",
    "    \"\"\"Apply feature engineering to all rows in the dataset.\"\"\"\n",
    "    features = df.apply(calculate_features, axis=1)\n",
    "    features_df = pd.DataFrame(features.tolist())\n",
    "    \n",
    "    # Ensure all features are numeric\n",
    "    for col in features_df.columns:\n",
    "        features_df[col] = pd.to_numeric(features_df[col], errors='coerce').fillna(0)\n",
    "    \n",
    "    return pd.concat([df, features_df], axis=1)\n",
    "\n",
    "# ================================\n",
    "# Step 2: Graph Data Preparation\n",
    "# ================================\n",
    "def create_graph(row, feature_columns):\n",
    "    \"\"\"Create a graph from a single row of the dataset.\"\"\"\n",
    "    sequence = row[\"sequence\"]\n",
    "    label = row[\"efficacy\"]\n",
    "\n",
    "    # Node features: One-hot encoding of nucleotides (A, U, C, G)\n",
    "    one_hot = {\"A\": [1, 0, 0, 0], \"U\": [0, 1, 0, 0], \"C\": [0, 0, 1, 0], \"G\": [0, 0, 0, 1]}\n",
    "    x = torch.tensor([one_hot[base] for base in sequence], dtype=torch.float)\n",
    "\n",
    "    # Edges: Connect adjacent nucleotides (bidirectional)\n",
    "    edge_index = torch.tensor(\n",
    "        [[i, i + 1] for i in range(len(sequence) - 1)] +\n",
    "        [[i + 1, i] for i in range(len(sequence) - 1)],\n",
    "        dtype=torch.long\n",
    "    ).t().contiguous()\n",
    "\n",
    "    # Global features (add unsqueeze here)\n",
    "    global_features = torch.tensor(\n",
    "        [row[col] for col in feature_columns],\n",
    "        dtype=torch.float\n",
    "    ).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    return Data(\n",
    "        x=x,\n",
    "        edge_index=edge_index,\n",
    "        y=torch.tensor([label], dtype=torch.float).view(-1, 1),\n",
    "        global_features=global_features\n",
    "    )\n",
    "\n",
    "\n",
    "def prepare_graph_data(df, feature_columns):\n",
    "    \"\"\"Convert the dataset into graph objects.\"\"\"\n",
    "    return [create_graph(row, feature_columns) for _, row in df.iterrows()]\n",
    "\n",
    "# ================================\n",
    "# Step 3: Define GNN Model\n",
    "# ================================\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, num_node_features, num_global_features, hidden_dim):\n",
    "        super(GNN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_node_features, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.fc_global = torch.nn.Linear(num_global_features, hidden_dim)\n",
    "        self.fc1 = torch.nn.Linear(hidden_dim + hidden_dim, hidden_dim)\n",
    "        self.fc2 = torch.nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = global_mean_pool(x, data.batch)\n",
    "\n",
    "        global_features = F.relu(self.fc_global(data.global_features))\n",
    "\n",
    "        combined = torch.cat([x, global_features], dim=1)\n",
    "        combined = F.relu(self.fc1(combined))\n",
    "        return self.fc2(combined)\n",
    "\n",
    "# ================================\n",
    "# Step 4: Training and Evaluation\n",
    "# ================================\n",
    "def train_model(model, train_loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "# Main Execution\n",
    "# ================================\n",
    "# Load efficacy data\n",
    "efficacy_df = pd.read_csv(\"sirna_mrna_efficacy.csv\")\n",
    "\n",
    "# Load siRNA sequences from the FASTA file\n",
    "sirna_sequences = []\n",
    "with open(\"sirna_1.fas\", \"r\") as fasta_file:\n",
    "    for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "        sirna_sequences.append({\"siRNA\": record.id, \"sequence\": str(record.seq).upper()})\n",
    "\n",
    "sirna_df = pd.DataFrame(sirna_sequences)\n",
    "\n",
    "# Merge siRNA sequences into the efficacy dataset\n",
    "merged_df = pd.merge(sirna_df, efficacy_df, on=\"siRNA\", how=\"inner\")\n",
    "\n",
    "# Reorder columns to place 'sequence' between 'siRNA' and 'efficacy'\n",
    "columns = [\"siRNA\", \"sequence\", \"efficacy\"]\n",
    "merged_df = merged_df[columns]\n",
    "\n",
    "# Feature engineering\n",
    "data_with_features = prepare_feature_data(merged_df)\n",
    "\n",
    "# Extract global feature columns, excluding 'mRNA'\n",
    "feature_columns = list(data_with_features.columns.difference([\"sequence\", \"efficacy\", \"siRNA\"]))\n",
    "\n",
    "# Prepare graph data\n",
    "graph_data = prepare_graph_data(data_with_features, feature_columns)\n",
    "\n",
    "# DataLoader\n",
    "loader = DataLoader(graph_data, batch_size=2, shuffle=True)\n",
    "\n",
    "# Model, optimizer, and loss function\n",
    "num_global_features = len(feature_columns)\n",
    "model = GNN(num_node_features=4, num_global_features=num_global_features, hidden_dim=16)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(50):\n",
    "    train_loss = train_model(model, loader, optimizer, criterion)\n",
    "    print(f\"Epoch {epoch+1}, Loss: {train_loss:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
